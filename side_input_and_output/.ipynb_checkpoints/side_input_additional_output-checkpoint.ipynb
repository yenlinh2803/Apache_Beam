{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import apache_beam as beam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149633CM\n",
      "212539MU\n",
      "231555ZZ\n",
      "704275DC\n",
      "['149633CM', '212539MU', '231555ZZ', '704275DC']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.io.filebasedsink:Deleting 1 existing files in target path matching: -*-of-%(num_shards)05d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('503996WI,Edouard', 31)\r\n",
      "('957149WC,Kyle', 31)\r\n",
      "('241316NX,Kumiko', 31)\r\n",
      "('796656IE,Gaston', 31)\r\n",
      "('718737IX,Ayumi', 30)\r\n"
     ]
    }
   ],
   "source": [
    "side_list = []\n",
    "with open ('exclude_ids.txt','r') as my_file:\n",
    "    for line in my_file:\n",
    "        print(line.rstrip())\n",
    "        side_list.append(line.rstrip())\n",
    "print(side_list)\n",
    "\n",
    "p = beam.Pipeline()\n",
    "\n",
    "class FilterUsingLength(beam.DoFn):\n",
    "    def process(self, element, side_list, lower_bound,upper_bound=float('inf')):\n",
    "        user_id = element.split(',')[0]\n",
    "        name = element.split(',')[1]\n",
    "        element_list = element.split(',')\n",
    "#         print(\"user_id: \",user_id)\n",
    "#         print(\"name: \",name)\n",
    "#         print(\"element_list: \",element_list)\n",
    "#         user_id= user_id.decode('utf-8','ignore').encode(\"utf-8\")\n",
    "        if (lower_bound <= len(name)<= upper_bound) and user_id not in side_list:\n",
    "            return [element_list]\n",
    "class PairEmployees(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        return [(element[0]+\",\"+element[1],1)]\n",
    "    \n",
    "class Counting(beam.DoFn):\n",
    "    def process(self, element):\n",
    "        (key, values) = element\n",
    "        return [(key,sum(values))]\n",
    "        \n",
    "# using ParDo to filter names with length between 3 and 10\n",
    "small_names = (\n",
    "    p\n",
    "    |\"Read from text file\" >> beam.io.ReadFromText('dept_data.txt')\n",
    "    |\"ParDo with side inputs\" >> beam.ParDo(FilterUsingLength(),side_list,3,10) \n",
    "    | beam.Filter(lambda record: record[3] == \"Accounts\")\n",
    "#     | beam.Filter(lambda record: (record[0]+\" \"+record[1],1))\n",
    "    |beam.ParDo(PairEmployees())\n",
    "    |'Group '>> beam.GroupByKey()\n",
    "    |'Sum using ParDo'>> beam.ParDo(Counting())\n",
    "#     |'Group '>> beam.GroupByKey()\n",
    "#     | beam.CombinePerKey(sum)\n",
    "    |'Write results' >> beam.io.WriteToText('data/out_new_final')\n",
    ")\n",
    "\n",
    "p.run()\n",
    "!{('head -n 20 data/out_new_final-00000-of-00001')}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ADDITIONAL + OUTPUT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DoFn function\n",
    "class ProcessWords(beam.DoFn):\n",
    "    def process(self, element, cutoff_length, marker):\n",
    "        name = element.split(',')[1]\n",
    "        if len(name) <= cutoff_length:\n",
    "            return [beam.pvalue.TaggedOutput('Short_Names',name)]\n",
    "        else:\n",
    "            return [beam.pvalue.TaggedOutput('Long_Names',name)]\n",
    "        if name.startswith(marker):\n",
    "            return name "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = beam.Pipeline()\n",
    "\n",
    "results = (\n",
    "    p\n",
    "    |beam.io.ReadFromText('dept_data.txt')\n",
    "    |beam.ParDo(ProcessWords(), cutoff_length=4, marker='A').with_outputs('Short_Names','Long_Names',main='Names_A')\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x120dc5590>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_collection = results.Short_Names\n",
    "long_collection = results.Long_Names\n",
    "startA_collection = results.Names_A  \n",
    "\n",
    "# write to file  \n",
    "short_collection | 'Write 1'>> beam.io.WriteToText('data/short')\n",
    "\n",
    "# write to file\n",
    "long_collection | 'Write 2'>> beam.io.WriteToText('data/long')\n",
    "\n",
    "# write to file\n",
    "startA_collection | 'Write 3'>> beam.io.WriteToText('data/start_a')\n",
    "\n",
    "p.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
